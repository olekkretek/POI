{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "377cffe4-df55-4be2-a9cf-f0b7cb3d920f",
      "cell_type": "markdown",
      "source": [
        "# Laboratorium ćwiczenie 3 - Programowanie w obliczeniach inteligentnych\n",
        "Autor: Aleksander Kretek 259130"
      ],
      "metadata": {
        "id": "377cffe4-df55-4be2-a9cf-f0b7cb3d920f"
      }
    },
    {
      "id": "dea9600d-b0df-4d5c-94ac-fffe2fedc331",
      "cell_type": "markdown",
      "source": [
        "1. Celem tego ćwiczenia było wykonanie zdjęć różnych rodzajów jednorodnych powierzchni.Następnie napisanie algorytmu służącego do wczytywanie ów zdjęć i wycinania z nich próbek(wymiary: 128x128).\n",
        "2. Wycięte próbki następnie zapisać w odpowiednich katalogach.\n",
        "3. Kolejnym krokiem było napisanie algorytmu do wczytywania próbek i wyznaczania dla nich cech tekstur na podstawie modelu macierzy zdarzeń.\n",
        "Należało wyznaczyć następujące cechy:\n",
        "a. dissimilarity, correlation, contrast, energy, homogeneity, ASM.\n",
        "b. Przyjąć 3 odległości pikseli: 1, 3, 5\n",
        "c. oraz 4 kierunki: 0, 45, 90 I 135 stopni (zakładamy symetrię kierunków).\n",
        "d. Każdy wektor cech uzupełnić o nazwę kategorii tekstury\n",
        "4. Następnie zapisać zbiór wektorów danych do pliku csv.\n",
        "5. Ostatnim krokiem było napisanie skryptu służącego klasyfikacji wektorów cech z wykorzystaniem dowolnego algorytmu do klasyfikacji danych. Uczenie należało przeprowadzić dla wyodrębnionego zbioru treningowego, a testowanie dla zbioru testowego."
      ],
      "metadata": {
        "id": "dea9600d-b0df-4d5c-94ac-fffe2fedc331"
      }
    },
    {
      "id": "f11509db-a779-4446-9d69-1c670f7f38b2",
      "cell_type": "markdown",
      "source": [
        "# Biblioteki"
      ],
      "metadata": {
        "id": "f11509db-a779-4446-9d69-1c670f7f38b2"
      }
    },
    {
      "id": "f03e0d9b-0138-4727-b99e-370b214c7cca",
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import io, color\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import glob"
      ],
      "metadata": {
        "trusted": true,
        "id": "f03e0d9b-0138-4727-b99e-370b214c7cca"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4a9451cc-39a9-49db-8b29-d0f458b96fce",
      "cell_type": "markdown",
      "source": [
        "# Konfiguracja"
      ],
      "metadata": {
        "id": "4a9451cc-39a9-49db-8b29-d0f458b96fce"
      }
    },
    {
      "id": "4bec0232-dc0f-4ffe-a166-128bf2f69c4f",
      "cell_type": "markdown",
      "source": [
        "1. INPUT_IMAGE_DIR należy wpisać ścieżkę do katalogu, w którym znajdują się podkatalogi ze zdjęciami.\n",
        "2. PATCHES_OUTPUT_DIR należy wpisać ścieżkę do katalogu, w którym zapisane zostaną próbki.\n",
        "3. FEATURES_CSV_FILE należy wpisać ścieżkę do pliku, w którym zapisane zostaną cechy próbek."
      ],
      "metadata": {
        "id": "4bec0232-dc0f-4ffe-a166-128bf2f69c4f"
      }
    },
    {
      "id": "9d5bd864-aa6c-4b42-8d9d-f37bd06912de",
      "cell_type": "code",
      "source": [
        "INPUT_IMAGE_DIR = '/content/sample_data/zdjecia'  # Obrazy oryginalne\n",
        "PATCHES_OUTPUT_DIR = '/content/sample_data/wycinki'   # Katalog, gdzie zapisane zostaną wycięte próbki\n",
        "FEATURES_CSV_FILE = '/content/sample_data/features.csv' # Plik CSV do zapisu cech\n",
        "PATCH_SIZE = (128, 128)                 # Rozmiar wycinanych próbek (wysokość, szerokość)\n",
        "GLCM_DISTANCES = [1, 3, 5]              # Odległości dla GLCM\n",
        "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4] # Kąty dla GLCM (0, 45, 90, 135 stopni)\n",
        "GLCM_LEVELS = 64                        # Liczba poziomów szarości"
      ],
      "metadata": {
        "scrolled": true,
        "jp-MarkdownHeadingCollapsed": true,
        "trusted": true,
        "id": "9d5bd864-aa6c-4b42-8d9d-f37bd06912de"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "02f48a5a-1f25-405b-bed3-bd1520563fe6",
      "cell_type": "markdown",
      "source": [
        "# Wczytywanie obrazów i wycinanie próbek"
      ],
      "metadata": {
        "id": "02f48a5a-1f25-405b-bed3-bd1520563fe6"
      }
    },
    {
      "id": "a67ef6db-1252-4609-9457-1ad7484ec1e7",
      "cell_type": "markdown",
      "source": [
        "1. Funkcja przeszukuje wszystkie podkatalogi w katalogu input_dir.\n",
        "2. Wycina próbki o określonym rozmiarze (patch_h, patch_w) z każdego obrazu.\n",
        "3. Zapisuje próbki w odpowiednich podkatalogach w katalogu output_dir.\n",
        "4. Każda próbka jest zapisywana z unikalną nazwą opartą na oryginalnej nazwie pliku i położeniu wycinka (r, c)."
      ],
      "metadata": {
        "id": "a67ef6db-1252-4609-9457-1ad7484ec1e7"
      }
    },
    {
      "id": "7c638ad2-07c7-45a7-a540-4bc846494728",
      "cell_type": "code",
      "source": [
        "def extract_patches(input_dir, output_dir, patch_h, patch_w):\n",
        "    # Tworzenie katalogów na wycinki o ile nie istnieją\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    categories = [d for d in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, d))]\n",
        "\n",
        "    total_patches_saved = 0\n",
        "    # Przetwarzanie każdej kategorii obrazów\n",
        "    for category in categories:\n",
        "        category_input_path = os.path.join(input_dir, category)\n",
        "        category_output_path = os.path.join(output_dir, category)\n",
        "        os.makedirs(category_output_path, exist_ok=True)\n",
        "        # Wyszukuje wszystkie pliki graficzne w formatach\n",
        "        image_files = glob.glob(os.path.join(category_input_path, '*.png')) + \\\n",
        "                      glob.glob(os.path.join(category_input_path, '*.jpg')) + \\\n",
        "                      glob.glob(os.path.join(category_input_path, '*.jpeg')) + \\\n",
        "                      glob.glob(os.path.join(category_input_path, '*.bmp')) + \\\n",
        "                      glob.glob(os.path.join(category_input_path, '*.tif'))\n",
        "\n",
        "        category_patches_count = 0\n",
        "        # Wczytywanie obrazu, pobieranie jego wymiarów, pobiera nazwe pliku\n",
        "        for img_path in image_files:\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "\n",
        "                img_h, img_w = img.shape[:2]\n",
        "                img_filename = os.path.basename(img_path)\n",
        "                img_name_part = os.path.splitext(img_filename)[0]\n",
        "                # Wycinanie próbek\n",
        "                for r in range(0, img_h - patch_h + 1, patch_h):\n",
        "                    for c in range(0, img_w - patch_w + 1, patch_w):\n",
        "                        patch = img[r:r + patch_h, c:c + patch_w]\n",
        "\n",
        "                        # Zapisywanie próbki\n",
        "                        patch_filename = f\"{img_name_part}_patch_{r:04d}_{c:04d}.png\"\n",
        "                        patch_output_path = os.path.join(category_output_path, patch_filename)\n",
        "                        cv2.imwrite(patch_output_path, patch)\n",
        "                        category_patches_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"BŁĄD podczas przetwarzania obrazu {img_path}: {e}\")\n",
        "\n",
        "        print(f\"Zapisano {category_patches_count} próbek dla kategorii '{category}'.\")\n",
        "        total_patches_saved += category_patches_count"
      ],
      "metadata": {
        "trusted": true,
        "id": "7c638ad2-07c7-45a7-a540-4bc846494728"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "db4b3e1c-2b88-4847-b160-935c0a23b013",
      "cell_type": "markdown",
      "source": [
        "# Wczytywanie próbek i obliczanie cech GLCM"
      ],
      "metadata": {
        "id": "db4b3e1c-2b88-4847-b160-935c0a23b013"
      }
    },
    {
      "id": "90886c4e-98fe-40e2-ad14-9f037bc7e040",
      "cell_type": "markdown",
      "source": [
        "Funkcja calculate_glcm_features przetwarza wycięte próbki tekstur:\n",
        "\n",
        "1. Wczytuje każdą próbkę z podkatalogów w patches_dir.\n",
        "\n",
        "2. Przekształca obraz do skali szarości.\n",
        "\n",
        "3. Zmniejsza głębię jasności do levels.\n",
        "\n",
        "4. Oblicza macierz GLCM dla zadanych odległości (distances) i kątów (angles). Macierz jest symetryczna i normalizowana.\n",
        "\n",
        "5. Z macierzy GLCM wyznacza następujące cechy: dissimilarity, correlation, contrast, energy, homogeneity, ASM. Dla każdej z tych cech obliczana jest średnia wartość dla wszystkich kierunków (kątów) przy danej odległości.\n",
        "\n",
        "6. Każdy wektor cech jest uzupełniany o nazwę kategorii tekstury oraz nazwę pliku próbki.\n",
        "\n",
        "7. Zwraca listę słowników, gdzie każdy słownik reprezentuje wektor cech jednej próbki."
      ],
      "metadata": {
        "id": "90886c4e-98fe-40e2-ad14-9f037bc7e040"
      }
    },
    {
      "id": "574cda74-f70e-49e0-bf43-afed210863a6",
      "cell_type": "code",
      "source": [
        "def calculate_glcm_features(patches_dir, distances, angles, levels):\n",
        "    # Pobieranie listy podkatalogów z katalogu, w którym znajdują się wycinki\n",
        "    categories = [d for d in os.listdir(patches_dir) if os.path.isdir(os.path.join(patches_dir, d))]\n",
        "\n",
        "    all_features = []\n",
        "    properties = ['dissimilarity', 'correlation', 'contrast', 'energy', 'homogeneity', 'ASM']\n",
        "    # Iteracja po każdym podkatalogu\n",
        "    for category in categories:\n",
        "        print(f\"Przetwarzanie kategorii: {category}\")\n",
        "        category_path = os.path.join(patches_dir, category)\n",
        "        patch_files = glob.glob(os.path.join(category_path, '*.png'))\n",
        "\n",
        "        processed_patches = 0\n",
        "        # Iteracja po każdej próbce\n",
        "        for patch_path in patch_files:\n",
        "            try:\n",
        "                patch = io.imread(patch_path)\n",
        "                # Konwersja do skali szarości\n",
        "                if patch.ndim == 3:\n",
        "                    patch_gray = color.rgb2gray(patch)\n",
        "                elif patch.ndim == 2:\n",
        "                    patch_gray = patch\n",
        "                else:\n",
        "                    continue\n",
        "                if patch_gray.max() <= 1.0:\n",
        "                     patch_gray = (patch_gray * 255).astype(np.uint8)\n",
        "                else:\n",
        "                     patch_gray = patch_gray.astype(np.uint8)\n",
        "                img_quantized = np.floor(patch_gray / 256. * levels).astype(np.uint8)\n",
        "\n",
        "                # Obliczenie macierzy GLCM\n",
        "                glcm = graycomatrix(img_quantized,\n",
        "                                    distances=distances,\n",
        "                                    angles=angles,\n",
        "                                    levels=levels,\n",
        "                                    symmetric=True,\n",
        "                                    normed=True)\n",
        "\n",
        "                # Obliczenie cech GLCM\n",
        "                feature_vector = {'category': category, 'patch_file': os.path.basename(patch_path)}\n",
        "                for prop in properties:\n",
        "                    prop_values = graycoprops(glcm, prop)\n",
        "                    for i, dist in enumerate(distances):\n",
        "                        feature_vector[f'{prop}_d{dist}'] = np.mean(prop_values[i, :])\n",
        "                # Dodanie cech do listy \"all_features\"\n",
        "                all_features.append(feature_vector)\n",
        "                processed_patches += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"BŁĄD podczas przetwarzania próbki {patch_path}: {e}\")\n",
        "\n",
        "    return all_features"
      ],
      "metadata": {
        "trusted": true,
        "id": "574cda74-f70e-49e0-bf43-afed210863a6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "903c95b2-318e-4dd2-babf-f45e17245f72",
      "cell_type": "markdown",
      "source": [
        "# Zapis wektorów cech do pliku CSV\n",
        "1. Funkcja save_features_to_csv wykorzystuje bibliotekę Pandas do zapisania listy wektorów cech (otrzymanej z calculate_glcm_features) do pliku CSV."
      ],
      "metadata": {
        "id": "903c95b2-318e-4dd2-babf-f45e17245f72"
      }
    },
    {
      "id": "e9b64f2f-eefc-4020-8872-bbe1ace28749",
      "cell_type": "code",
      "source": [
        "def save_features_to_csv(features_list, csv_filepath):\n",
        "    try:\n",
        "        df = pd.DataFrame(features_list)\n",
        "        if 'category' in df.columns:\n",
        "             cols = ['category'] + [col for col in df.columns if col != 'category']\n",
        "             df = df[cols]\n",
        "        df.to_csv(csv_filepath, index=False)\n",
        "        print(f\"Zapisano {len(df)} wektorów cech do pliku: {csv_filepath}\")\n",
        "    except Exception as e:\n",
        "        print(f\"BŁĄD podczas zapisywania pliku CSV {csv_filepath}: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "e9b64f2f-eefc-4020-8872-bbe1ace28749"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c983ce48-992d-4e7d-a3c0-5dc408271d66",
      "cell_type": "markdown",
      "source": [
        "# Klasyfikacja wektorów cech"
      ],
      "metadata": {
        "id": "c983ce48-992d-4e7d-a3c0-5dc408271d66"
      }
    },
    {
      "id": "575d82de-f11e-4b54-ac1b-b2d7ce4a05cf",
      "cell_type": "markdown",
      "source": [
        "Funkcja classify_features realizuje proces klasyfikacji:\n",
        "1. Wczytuje dane z pliku CSV.\n",
        "2. Przygotowuje dane:\n",
        "- X: wektory cech (usuwając kolumny category i patch_file).\n",
        "- y: etykiety kategorii.\n",
        "  \n",
        "3. Koduje etykiety tekstowe na wartości liczbowe za pomocą LabelEncoder.\n",
        "4. Dzieli dane na zbiór treningowy i testowy (train_test_split) z zachowaniem proporcji klas (stratify=y).\n",
        "5. Wybiera, trenuje i testuje klasyfikator:\n",
        "- K-Najbliższych Sąsiadów (KNeighborsClassifier).\n",
        "- Maszyna Wektorów Nośnych (SVC).\n",
        "  \n",
        "6. Oblicza i wyświetla dokładność (accuracy_score) klasyfikatora na zbiorze testowym."
      ],
      "metadata": {
        "id": "575d82de-f11e-4b54-ac1b-b2d7ce4a05cf"
      }
    },
    {
      "id": "63e3414a-6456-4318-af05-2efb049ac5e4",
      "cell_type": "code",
      "source": [
        "def classify_features(csv_filepath, test_size=0, random_state=0, classifier_type=0):\n",
        "\n",
        "    try:\n",
        "        # Wczytywanie danych\n",
        "        df = pd.read_csv(csv_filepath)\n",
        "        print(f\"Wczytano {len(df)} wektorów cech z {csv_filepath}.\")\n",
        "\n",
        "        if df.empty:\n",
        "            print(\"BŁĄD: Plik CSV jest pusty.\")\n",
        "            return\n",
        "        if 'category' not in df.columns:\n",
        "            print(\"BŁĄD: Brak kolumny 'category' w pliku CSV.\")\n",
        "            return\n",
        "\n",
        "        # Przygotowanie danych\n",
        "        X = df.drop(['category', 'patch_file'], axis=1) # Cechy\n",
        "        y_raw = df['category']                     # Etykiety\n",
        "\n",
        "        # Kodowanie etykiet (zamiana nazw kategorii na liczby)\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(y_raw)\n",
        "\n",
        "        # Podział na zbiór treningowy i testowy\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "            test_size=test_size,\n",
        "            random_state=random_state,\n",
        "            stratify=y\n",
        "        )\n",
        "        print(f\"Podzielono dane na zbiór treningowy ({len(X_train)} próbek) i testowy ({len(X_test)} próbek).\")\n",
        "\n",
        "        # Wybór i trenowanie klasyfikatora\n",
        "        if classifier_type.lower() == 'knn':\n",
        "            print(\"(KNN):\")\n",
        "            model = KNeighborsClassifier(n_neighbors=5)\n",
        "        elif classifier_type.lower() == 'svm':\n",
        "            print(\"(SVM):\")\n",
        "            model = SVC(kernel='linear',  random_state=random_state)\n",
        "        # Trenowanie modelu\n",
        "        model.fit(X_train, y_train)\n",
        "        # Predykcja na zbiorze testowym\n",
        "        y_pred = model.predict(X_test)\n",
        "        # Ocena dokładności modelu\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Dokładność (Accuracy) na zbiorze testowym: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"BŁĄD podczas klasyfikacji: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "63e3414a-6456-4318-af05-2efb049ac5e4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5e693cdf-e623-461b-84f7-dbee3bad45c1",
      "cell_type": "markdown",
      "source": [
        "# Wywołanie funkcji"
      ],
      "metadata": {
        "id": "5e693cdf-e623-461b-84f7-dbee3bad45c1"
      }
    },
    {
      "id": "6dd7b63d-fdcb-47d5-9a14-c59268ddfbcf",
      "cell_type": "raw",
      "source": [
        "Za pomocą zmiany wartości zmiennej \"test_size\" można określić jaka część próbek zostanie przeznaczona na zbiór testowy a jaka na zbiór treningowy."
      ],
      "metadata": {
        "id": "6dd7b63d-fdcb-47d5-9a14-c59268ddfbcf"
      }
    },
    {
      "id": "f0046fbd-bda2-414b-8f3f-b27a379ca269",
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    extract_patches(INPUT_IMAGE_DIR, PATCHES_OUTPUT_DIR, PATCH_SIZE[0], PATCH_SIZE[1])\n",
        "    features = calculate_glcm_features(PATCHES_OUTPUT_DIR, GLCM_DISTANCES, GLCM_ANGLES, GLCM_LEVELS)\n",
        "    save_features_to_csv(features, FEATURES_CSV_FILE)\n",
        "    classify_features(FEATURES_CSV_FILE, test_size=0.90, random_state=42, classifier_type='svm')\n",
        "    classify_features(FEATURES_CSV_FILE, test_size=0.2, random_state=42, classifier_type='knn')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0046fbd-bda2-414b-8f3f-b27a379ca269",
        "outputId": "05e8534a-e9bf-4901-9b6b-e93daaca4e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zapisano 40 próbek dla kategorii 'tynk'.\n",
            "Zapisano 25 próbek dla kategorii 'laminat'.\n",
            "Zapisano 0 próbek dla kategorii '.ipynb_checkpoints'.\n",
            "Zapisano 16 próbek dla kategorii 'gres'.\n",
            "Zapisano 9 próbek dla kategorii 'carbon'.\n",
            "Przetwarzanie kategorii: tynk\n",
            "Przetwarzanie kategorii: laminat\n",
            "Przetwarzanie kategorii: .ipynb_checkpoints\n",
            "Przetwarzanie kategorii: gres\n",
            "Przetwarzanie kategorii: carbon\n",
            "Zapisano 90 wektorów cech do pliku: /content/sample_data/features.csv\n",
            "Wczytano 90 wektorów cech z /content/sample_data/features.csv.\n",
            "Podzielono dane na zbiór treningowy (9 próbek) i testowy (81 próbek).\n",
            "(SVM):\n",
            "Dokładność (Accuracy) na zbiorze testowym: 0.8025 (80.25%)\n",
            "Wczytano 90 wektorów cech z /content/sample_data/features.csv.\n",
            "Podzielono dane na zbiór treningowy (72 próbek) i testowy (18 próbek).\n",
            "(KNN):\n",
            "Dokładność (Accuracy) na zbiorze testowym: 0.8889 (88.89%)\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}